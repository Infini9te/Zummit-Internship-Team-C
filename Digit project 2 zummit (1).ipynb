{"cells":[{"cell_type":"code","execution_count":null,"id":"45377f09","metadata":{"id":"45377f09"},"outputs":[],"source":["from mnist import MNIST"]},{"cell_type":"code","execution_count":null,"id":"4b7a24e6","metadata":{"id":"4b7a24e6"},"outputs":[],"source":["data = MNIST(path='Desktop/data', return_type='numpy')\n","data.select_emnist('letters')\n","X, y = data.load_training()"]},{"cell_type":"code","execution_count":null,"id":"9bbbdc93","metadata":{"id":"9bbbdc93","outputId":"9cafb160-58e4-4ea5-84ba-db36829c903a"},"outputs":[{"data":{"text/plain":["((124800, 784), (124800,))"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["X.shape, y.shape"]},{"cell_type":"code","execution_count":null,"id":"3a3ba840","metadata":{"id":"3a3ba840","outputId":"4000d838-7091-40c3-a7c0-ef53fb25c839"},"outputs":[{"data":{"text/plain":["784"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["28*28"]},{"cell_type":"code","execution_count":null,"id":"34895b31","metadata":{"id":"34895b31"},"outputs":[],"source":["X = X.reshape(124800, 28, 28)\n","y = y.reshape(124800, 1)"]},{"cell_type":"code","execution_count":null,"id":"4023d672","metadata":{"id":"4023d672"},"outputs":[],"source":["y = y-1"]},{"cell_type":"code","execution_count":null,"id":"02d37d4b","metadata":{"id":"02d37d4b"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=50)\n"]},{"cell_type":"code","execution_count":null,"id":"4cb87d4a","metadata":{"id":"4cb87d4a"},"outputs":[],"source":["X_train = X_train.astype('float32')/255\n","X_test = X_test.astype('float32')/255"]},{"cell_type":"code","execution_count":null,"id":"cb65e59a","metadata":{"id":"cb65e59a"},"outputs":[],"source":["from keras.utils import np_utils\n","y_train = np_utils.to_categorical(y_train, num_classes = 26)\n","y_test = np_utils.to_categorical(y_test, num_classes = 26)"]},{"cell_type":"code","execution_count":null,"id":"f24bde5d","metadata":{"id":"f24bde5d"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten"]},{"cell_type":"code","execution_count":null,"id":"40c8c7b0","metadata":{"id":"40c8c7b0"},"outputs":[],"source":["model = Sequential()\n","model.add(Flatten(input_shape = (28,28)))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2)) # preventing overfitting\n","model.add(Dense(512, activation = 'relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(26, activation='softmax'))"]},{"cell_type":"code","execution_count":null,"id":"0b096ded","metadata":{"id":"0b096ded","outputId":"3f376eaa-5d65-48ec-ad65-91a95f2287b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           (None, 784)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               401920    \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 512)               262656    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 26)                13338     \n","                                                                 \n","=================================================================\n","Total params: 677,914\n","Trainable params: 677,914\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()\n"]},{"cell_type":"code","execution_count":null,"id":"3e69ad64","metadata":{"id":"3e69ad64"},"outputs":[],"source":["model.compile(loss= 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"b1ec70c1","metadata":{"id":"b1ec70c1","outputId":"a8aeec7c-f922-40c2-cf49-7cd86be9c898"},"outputs":[{"name":"stdout","output_type":"stream","text":["Before training, test accuracy is 3.8381408900022507\n"]}],"source":["score = model.evaluate(X_test, y_test, verbose=0)\n","accuracy = 100*score[1]\n","print(\"Before training, test accuracy is\", accuracy)"]},{"cell_type":"code","execution_count":null,"id":"af5a857b","metadata":{"id":"af5a857b"},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":null,"id":"d52b3259","metadata":{"id":"d52b3259","outputId":"76d91e32-20ea-436f-fb07-fb280529d284"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","624/624 [==============================] - ETA: 0s - loss: 0.8023 - accuracy: 0.7586\n","Epoch 1: val_loss improved from inf to 0.44014, saving model to best_model.h5\n","624/624 [==============================] - 22s 32ms/step - loss: 0.8023 - accuracy: 0.7586 - val_loss: 0.4401 - val_accuracy: 0.8606\n","Epoch 2/10\n","623/624 [============================>.] - ETA: 0s - loss: 0.4232 - accuracy: 0.8651\n","Epoch 2: val_loss improved from 0.44014 to 0.35561, saving model to best_model.h5\n","624/624 [==============================] - 21s 34ms/step - loss: 0.4232 - accuracy: 0.8651 - val_loss: 0.3556 - val_accuracy: 0.8889\n","Epoch 3/10\n","624/624 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.8878\n","Epoch 3: val_loss improved from 0.35561 to 0.31184, saving model to best_model.h5\n","624/624 [==============================] - 30s 47ms/step - loss: 0.3403 - accuracy: 0.8878 - val_loss: 0.3118 - val_accuracy: 0.9026\n","Epoch 4/10\n","623/624 [============================>.] - ETA: 0s - loss: 0.2942 - accuracy: 0.9011\n","Epoch 4: val_loss improved from 0.31184 to 0.29955, saving model to best_model.h5\n","624/624 [==============================] - 26s 41ms/step - loss: 0.2942 - accuracy: 0.9011 - val_loss: 0.2995 - val_accuracy: 0.9018\n","Epoch 5/10\n","624/624 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.9104\n","Epoch 5: val_loss did not improve from 0.29955\n","624/624 [==============================] - 26s 41ms/step - loss: 0.2640 - accuracy: 0.9104 - val_loss: 0.2998 - val_accuracy: 0.9038\n","Epoch 6/10\n","623/624 [============================>.] - ETA: 0s - loss: 0.2403 - accuracy: 0.9164\n","Epoch 6: val_loss improved from 0.29955 to 0.29189, saving model to best_model.h5\n","624/624 [==============================] - 21s 33ms/step - loss: 0.2405 - accuracy: 0.9164 - val_loss: 0.2919 - val_accuracy: 0.9096\n","Epoch 7/10\n","623/624 [============================>.] - ETA: 0s - loss: 0.2227 - accuracy: 0.9215\n","Epoch 7: val_loss improved from 0.29189 to 0.28369, saving model to best_model.h5\n","624/624 [==============================] - 19s 31ms/step - loss: 0.2228 - accuracy: 0.9214 - val_loss: 0.2837 - val_accuracy: 0.9126\n","Epoch 8/10\n","624/624 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.9262\n","Epoch 8: val_loss did not improve from 0.28369\n","624/624 [==============================] - 19s 30ms/step - loss: 0.2064 - accuracy: 0.9262 - val_loss: 0.2858 - val_accuracy: 0.9103\n","Epoch 9/10\n","623/624 [============================>.] - ETA: 0s - loss: 0.1899 - accuracy: 0.9312\n","Epoch 9: val_loss improved from 0.28369 to 0.27301, saving model to best_model.h5\n","624/624 [==============================] - 19s 30ms/step - loss: 0.1898 - accuracy: 0.9312 - val_loss: 0.2730 - val_accuracy: 0.9178\n","Epoch 10/10\n","624/624 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.9338\n","Epoch 10: val_loss did not improve from 0.27301\n","624/624 [==============================] - 25s 40ms/step - loss: 0.1825 - accuracy: 0.9338 - val_loss: 0.2835 - val_accuracy: 0.9125\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1dee2c77f40>"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["checkpointer = ModelCheckpoint(filepath = 'best_model.h5', verbose=1, save_best_only = True)\n","model.fit(X_train, y_train, batch_size = 128, epochs= 10, validation_split = 0.2, \n","          callbacks=[checkpointer], verbose=1, shuffle=True)"]},{"cell_type":"code","execution_count":null,"id":"084f44d9","metadata":{"id":"084f44d9"},"outputs":[],"source":["model.load_weights('best_model.h5')"]},{"cell_type":"code","execution_count":null,"id":"f12a3ae8","metadata":{"id":"f12a3ae8"},"outputs":[],"source":["score = model.evaluate(X_test, y_test, verbose=0)\n","accuracy = 100*score[1]"]},{"cell_type":"code","execution_count":null,"id":"a6066c8d","metadata":{"id":"a6066c8d","outputId":"eff7450f-b7c9-4ee8-e37a-27f5ed88a5a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy is  91.58653616905212\n"]}],"source":["print(\"Test accuracy is \", accuracy)"]},{"cell_type":"code","execution_count":null,"id":"16f43734","metadata":{"id":"16f43734"},"outputs":[],"source":["from keras.models import load_model\n"]},{"cell_type":"code","execution_count":null,"id":"bc318037","metadata":{"id":"bc318037"},"outputs":[],"source":["model = load_model('best_model.h5')"]},{"cell_type":"code","execution_count":null,"id":"da6ca71c","metadata":{"id":"da6ca71c"},"outputs":[],"source":["letters ={ 0:'a', 1:'b', 2:'c', 3:'d', 4:'e', 5:'f', 6:'g', 7:'h', 8:'i', 9:'j', 10:'k', 11:'l', \n","          12:'m', 13:'n', 14:'o', 15:'p', 16:'q', 17:'r', 18:'s', 19:'t', 20:'u', 21:'v', 22:'w', \n","          23:'x', 24:'y', 25:'z', 26:''}"]},{"cell_type":"code","execution_count":null,"id":"ce05b212","metadata":{"id":"ce05b212"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":null,"id":"f0ee8e20","metadata":{"id":"f0ee8e20"},"outputs":[],"source":["blueLower = np.array([100,60,60])\n","blueUpper = np.array([140,255,255])"]},{"cell_type":"code","execution_count":null,"id":"24132cb0","metadata":{"id":"24132cb0"},"outputs":[],"source":["kernel = np.ones((5,5), np.uint8)"]},{"cell_type":"code","execution_count":null,"id":"6739f4f6","metadata":{"id":"6739f4f6"},"outputs":[],"source":["blackboard = np.zeros((480,640, 3), dtype=np.uint8)\n","alphabet = np.zeros((200,200,3), dtype=np.uint8)"]},{"cell_type":"code","execution_count":null,"id":"02398c34","metadata":{"id":"02398c34"},"outputs":[],"source":["from collections import deque\n","points = deque(maxlen = 512)"]},{"cell_type":"code","execution_count":null,"id":"3318602b","metadata":{"id":"3318602b"},"outputs":[],"source":["import cv2 #pip install opencv-python\n","cap = cv2.VideoCapture(0)"]},{"cell_type":"code","execution_count":null,"id":"09bedf58","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"09bedf58","executionInfo":{"status":"error","timestamp":1677757153890,"user_tz":-330,"elapsed":11,"user":{"displayName":"aniket malviya","userId":"06013323772686351302"}},"outputId":"5c038ebe-76e1-438e-e854-499b7ce99d4c"},"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-1be25fc4e187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}],"source":["while True:\n","    ret, frame=cap.read()\n","    frame = cv2.flip(frame, 1)\n","    \n","    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    \n","    # Detecting which pixel value falls under blue color boundaries\n","    blue = cv2.inRange(hsv, blueLower, blueUpper)\n","    \n","    #erosion\n","    blue = cv2.erode(blue, kernel)\n","    #opening\n","    blue = cv2.morphologyEx(blue, cv2.MORPH_OPEN, kernel)\n","    #dilation\n","    blue = cv2.dilate(blue, kernel)\n","    \n","    # find countours in the image\n","    cnts , _ = cv2.findContours(blue, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","     \n","    center = None\n","    \n","    # if any countours were found\n","    if len(cnts) > 0:\n","        cnt = sorted(cnts, key = cv2.contourArea, reverse=True)[0]\n","        ((x,y), radius) = cv2.minEnclosingCircle(cnt)\n","        cv2.circle(frame, (int(x), int(y),), int(radius), (125,344,278), 2)\n","        \n","        M = cv2.moments(cnt)\n","        center = (int(M['m10']/M['m00']), int(M['m01']/M['m00']))\n","    \n","        points.appendleft(center)\n","        \n","    elif len(cnts) == 0:\n","        if len(points) != 0:\n","            blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n","            blur = cv2.medianBlur(blackboard_gray, 15)\n","            blur = cv2.GaussianBlur(blur, (5,5), 0)\n","            thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n","            #cv2.imshow(\"Thresh\", thresh)\n","            \n","    \n","    cv2.imshow(\"Alphabet Recognition System\", frame)\n","    \n","    if cv2.waitKey(1)==13: #if I press enter\n","        break\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","id":"ec550970","metadata":{"id":"ec550970"},"source":["cap = cv2.VideoCapture(0)\n","prediction = 26"]},{"cell_type":"code","execution_count":null,"id":"c271949a","metadata":{"id":"c271949a"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","prediction = 26"]},{"cell_type":"code","execution_count":null,"id":"35e12fb4","metadata":{"id":"35e12fb4","outputId":"9ce91400-177f-41b7-c015-ed30b06bc037"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 666ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 45ms/step\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 56ms/step\n"]}],"source":["while True:\n","    ret, frame=cap.read()\n","    frame = cv2.flip(frame, 1)\n","    \n","    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    \n","    # Detecting which pixel value falls under blue color boundaries\n","    blue = cv2.inRange(hsv, blueLower, blueUpper)\n","    \n","    #erosion\n","    blue = cv2.erode(blue, kernel)\n","    #opening\n","    blue = cv2.morphologyEx(blue, cv2.MORPH_OPEN, kernel)\n","    #dilation\n","    blue = cv2.dilate(blue, kernel)\n","    \n","    # find countours in the image\n","    cnts , _ = cv2.findContours(blue, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","     \n","    center = None\n","    \n","    # if any countours were found\n","    if len(cnts) > 0:\n","        cnt = sorted(cnts, key = cv2.contourArea, reverse=True)[0]\n","        ((x,y), radius) = cv2.minEnclosingCircle(cnt)\n","        cv2.circle(frame, (int(x), int(y),), int(radius), (125,344,278), 2)\n","        \n","        M = cv2.moments(cnt)\n","        center = (int(M['m10']/M['m00']), int(M['m01']/M['m00']))\n","    \n","        points.appendleft(center)\n","        \n","    elif len(cnts) == 0:\n","        if len(points) != 0:\n","            blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n","            blur = cv2.medianBlur(blackboard_gray, 15)\n","            blur = cv2.GaussianBlur(blur, (5,5), 0)\n","            thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n","            #cv2.imshow(\"Thresh\", thresh)\n","            \n","            blackboard_cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[0]\n","            \n","            if len(blackboard_cnts)>=1:\n","                cnt = sorted(blackboard_cnts, key=cv2.contourArea, reverse=True)[0]\n","                \n","                if cv2.contourArea(cnt)>1000:\n","                    x,y,w,h = cv2.boundingRect(cnt)\n","                    alphabet = blackboard_gray[y-10:y+h+10,x-10:x+w+10]\n","                    try:\n","                        img = cv2.resize(alphabet, (28,28))\n","                    except cv2.error as e:\n","                        continue\n","                    \n","                    img = np.array(img)\n","                    img = img.astype('float32')/255\n","                    \n","                    prediction = model.predict(img.reshape(1,28,28))[0]\n","                    prediction = np.argmax(prediction)\n","                    \n","            # Empty the point deque and also blackboard\n","            points = deque(maxlen=512)\n","            blackboard = np.zeros((480,640, 3), dtype=np.uint8)\n","        \n","    # connect the detected points with line\n","    for i in range(1, len(points)):\n","        if points[i-1] is None or points[i] is None:\n","            continue\n","        cv2.line(frame, points[i-1], points[i], (0,0,0), 2)\n","        cv2.line(blackboard, points[i-1], points[i], (255,255,255), 8)\n","        \n","    \n","    cv2.putText(frame, \"Prediction: \" + str(letters[int(prediction)]), (20,400), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n","    \n","    \n","    cv2.imshow(\"Alphabet Recognition System\", frame)\n","    \n","    if cv2.waitKey(1)==13: #if I press enter\n","        break\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"id":"d26bb998","metadata":{"id":"d26bb998"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}