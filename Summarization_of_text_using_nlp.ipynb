{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZyCF3XYLa2E2",
        "outputId": "fda2a463-8f2d-404e-ccd5-05c6b325c179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.4\n",
            "    Uninstalling spacy-3.4.4:\n",
            "      Successfully uninstalled spacy-3.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed spacy-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "TLCynGE9a5-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42529603-310a-457c-9357-db1bf1cd28f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-06 04:59:17.924093: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.25.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.4.1\n",
            "    Uninstalling en-core-web-sm-3.4.1:\n",
            "      Successfully uninstalled en-core-web-sm-3.4.1\n",
            "Successfully installed en-core-web-sm-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gClUkKNcF212",
        "outputId": "b0199fba-9643-457a-a0da-351bd7573307"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = list(STOP_WORDS)"
      ],
      "metadata": {
        "id": "7mE7tdRAF_UN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "Xi_30CyfGBEb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Summarization is a process of automatically condensing and rewriting a large chunk of text to create a small, crisp summary. A summarization system should give the reader most of the information present in the original document while also ensuring that no information has been lost during condensation.The application of summarization systems is extensive, such as: helping the reader to get a quick understanding of an article, saving time for analysts and researchers in their information-gathering process, reducing the amount of written text that students need to read and understand (in educational contexts), and even increasing efficiency and productivity in business settingsSome systems for automatic summarization use full text in order to identify important sentences. Other systems use abstracts, key sentences or other summary-like structures when the full text is not available.Some automatic summarization systems produce summaries that are grammatically correct, while others tend to produce fragments of the original texts with some inserted sentences to help convey the main points. Some automatic summarization systems use a language model to capture the meaning of sentences and a grammatical model to ensure that they are syntactically correct; there are also hybrid approaches that combine both language models and grammar models.A trend in recent research has been towards using natural language processing (NLP) techniques for automated summarization of text in order to capture both the meaning and the style of the original document.Summarization systems can be categorized based on whether they produce their summaries by extracting or abstracting information from the full texts. Abstraction-based summarizers extract sentences that are representative of some selected portion of the full text, while extraction-based summarizers identify a set of key sentences that are most relevant to the topic of the document.The effectiveness of a summarization system depends on several factors, such as the type of text, the summarization algorithm used, and the user preferences. However, overall, summarization systems have been found to be effective in reducing the amount of text that readers need to read to get an understanding of the main points of a document.'"
      ],
      "metadata": {
        "id": "CdrZ0M3cGDZc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "l8632i-DGKQ-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [token.text for token in doc]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2s-lSjTIROJ",
        "outputId": "bd45b499-021b-4182-97fd-a5623f790481"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Summarization', 'is', 'a', 'process', 'of', 'automatically', 'condensing', 'and', 'rewriting', 'a', 'large', 'chunk', 'of', 'text', 'to', 'create', 'a', 'small', ',', 'crisp', 'summary', '.', 'A', 'summarization', 'system', 'should', 'give', 'the', 'reader', 'most', 'of', 'the', 'information', 'present', 'in', 'the', 'original', 'document', 'while', 'also', 'ensuring', 'that', 'no', 'information', 'has', 'been', 'lost', 'during', 'condensation', '.', 'The', 'application', 'of', 'summarization', 'systems', 'is', 'extensive', ',', 'such', 'as', ':', 'helping', 'the', 'reader', 'to', 'get', 'a', 'quick', 'understanding', 'of', 'an', 'article', ',', 'saving', 'time', 'for', 'analysts', 'and', 'researchers', 'in', 'their', 'information', '-', 'gathering', 'process', ',', 'reducing', 'the', 'amount', 'of', 'written', 'text', 'that', 'students', 'need', 'to', 'read', 'and', 'understand', '(', 'in', 'educational', 'contexts', ')', ',', 'and', 'even', 'increasing', 'efficiency', 'and', 'productivity', 'in', 'business', 'settingsSome', 'systems', 'for', 'automatic', 'summarization', 'use', 'full', 'text', 'in', 'order', 'to', 'identify', 'important', 'sentences', '.', 'Other', 'systems', 'use', 'abstracts', ',', 'key', 'sentences', 'or', 'other', 'summary', '-', 'like', 'structures', 'when', 'the', 'full', 'text', 'is', 'not', 'available', '.', 'Some', 'automatic', 'summarization', 'systems', 'produce', 'summaries', 'that', 'are', 'grammatically', 'correct', ',', 'while', 'others', 'tend', 'to', 'produce', 'fragments', 'of', 'the', 'original', 'texts', 'with', 'some', 'inserted', 'sentences', 'to', 'help', 'convey', 'the', 'main', 'points', '.', 'Some', 'automatic', 'summarization', 'systems', 'use', 'a', 'language', 'model', 'to', 'capture', 'the', 'meaning', 'of', 'sentences', 'and', 'a', 'grammatical', 'model', 'to', 'ensure', 'that', 'they', 'are', 'syntactically', 'correct', ';', 'there', 'are', 'also', 'hybrid', 'approaches', 'that', 'combine', 'both', 'language', 'models', 'and', 'grammar', 'models', '.', 'A', 'trend', 'in', 'recent', 'research', 'has', 'been', 'towards', 'using', 'natural', 'language', 'processing', '(', 'NLP', ')', 'techniques', 'for', 'automated', 'summarization', 'of', 'text', 'in', 'order', 'to', 'capture', 'both', 'the', 'meaning', 'and', 'the', 'style', 'of', 'the', 'original', 'document', '.', 'Summarization', 'systems', 'can', 'be', 'categorized', 'based', 'on', 'whether', 'they', 'produce', 'their', 'summaries', 'by', 'extracting', 'or', 'abstracting', 'information', 'from', 'the', 'full', 'texts', '.', 'Abstraction', '-', 'based', 'summarizers', 'extract', 'sentences', 'that', 'are', 'representative', 'of', 'some', 'selected', 'portion', 'of', 'the', 'full', 'text', ',', 'while', 'extraction', '-', 'based', 'summarizers', 'identify', 'a', 'set', 'of', 'key', 'sentences', 'that', 'are', 'most', 'relevant', 'to', 'the', 'topic', 'of', 'the', 'document', '.', 'The', 'effectiveness', 'of', 'a', 'summarization', 'system', 'depends', 'on', 'several', 'factors', ',', 'such', 'as', 'the', 'type', 'of', 'text', ',', 'the', 'summarization', 'algorithm', 'used', ',', 'and', 'the', 'user', 'preferences', '.', 'However', ',', 'overall', ',', 'summarization', 'systems', 'have', 'been', 'found', 'to', 'be', 'effective', 'in', 'reducing', 'the', 'amount', 'of', 'text', 'that', 'readers', 'need', 'to', 'read', 'to', 'get', 'an', 'understanding', 'of', 'the', 'main', 'points', 'of', 'a', 'document', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation = punctuation + '\\n'\n",
        "punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7vqDLeXoIdEI",
        "outputId": "a9b72806-6396-42ba-a91f-fabd8de00dae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies = {}\n",
        "for word in doc:\n",
        "    if word.text.lower() not in stopwords:\n",
        "       if word.text.lower() not in punctuation: \n",
        "          if word.text.lower() not in word_frequencies.keys():\n",
        "              word_frequencies[word.text] = 1\n",
        "          else:\n",
        "             word_frequencies[word.text] += 1"
      ],
      "metadata": {
        "id": "92-ZgDOnMozs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_frequencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0BR74HeOKHV",
        "outputId": "88d0cad2-80ff-476f-e0f4-df77529125c3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Summarization': 2, 'process': 2, 'automatically': 1, 'condensing': 1, 'rewriting': 1, 'large': 1, 'chunk': 1, 'text': 8, 'create': 1, 'small': 1, 'crisp': 1, 'summary': 2, 'summarization': 9, 'system': 2, 'reader': 2, 'information': 4, 'present': 1, 'original': 3, 'document': 4, 'ensuring': 1, 'lost': 1, 'condensation': 1, 'application': 1, 'systems': 7, 'extensive': 1, 'helping': 1, 'quick': 1, 'understanding': 2, 'article': 1, 'saving': 1, 'time': 1, 'analysts': 1, 'researchers': 1, 'gathering': 1, 'reducing': 2, 'written': 1, 'students': 1, 'need': 2, 'read': 2, 'understand': 1, 'educational': 1, 'contexts': 1, 'increasing': 1, 'efficiency': 1, 'productivity': 1, 'business': 1, 'settingsSome': 1, 'automatic': 3, 'use': 3, 'order': 2, 'identify': 2, 'important': 1, 'sentences': 6, 'abstracts': 1, 'key': 2, 'like': 1, 'structures': 1, 'available': 1, 'produce': 3, 'summaries': 2, 'grammatically': 1, 'correct': 2, 'tend': 1, 'fragments': 1, 'texts': 2, 'inserted': 1, 'help': 1, 'convey': 1, 'main': 2, 'points': 2, 'language': 3, 'model': 2, 'capture': 2, 'meaning': 2, 'grammatical': 1, 'ensure': 1, 'syntactically': 1, 'hybrid': 1, 'approaches': 1, 'combine': 1, 'models': 2, 'grammar': 1, 'trend': 1, 'recent': 1, 'research': 1, 'natural': 1, 'processing': 1, 'NLP': 1, 'techniques': 1, 'automated': 1, 'style': 1, 'categorized': 1, 'based': 3, 'extracting': 1, 'abstracting': 1, 'Abstraction': 1, 'summarizers': 2, 'extract': 1, 'representative': 1, 'selected': 1, 'portion': 1, 'extraction': 1, 'set': 1, 'relevant': 1, 'topic': 1, 'effectiveness': 1, 'depends': 1, 'factors': 1, 'type': 1, 'algorithm': 1, 'user': 1, 'preferences': 1, 'overall': 1, 'found': 1, 'effective': 1, 'readers': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_frequency = max(word_frequencies.values())"
      ],
      "metadata": {
        "id": "c5aY8yjmORez"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNiUwp--OxRy",
        "outputId": "78e7853a-73f8-4b13-fb95-404ea2239a54"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = word_frequencies[word]/max_frequency"
      ],
      "metadata": {
        "id": "TCA-bJArO2zz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_frequencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsMBE5XsSr7_",
        "outputId": "03ff60df-55a9-4223-ea7a-6239669d8cb4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Summarization': 0.2222222222222222, 'process': 0.2222222222222222, 'automatically': 0.1111111111111111, 'condensing': 0.1111111111111111, 'rewriting': 0.1111111111111111, 'large': 0.1111111111111111, 'chunk': 0.1111111111111111, 'text': 0.8888888888888888, 'create': 0.1111111111111111, 'small': 0.1111111111111111, 'crisp': 0.1111111111111111, 'summary': 0.2222222222222222, 'summarization': 1.0, 'system': 0.2222222222222222, 'reader': 0.2222222222222222, 'information': 0.4444444444444444, 'present': 0.1111111111111111, 'original': 0.3333333333333333, 'document': 0.4444444444444444, 'ensuring': 0.1111111111111111, 'lost': 0.1111111111111111, 'condensation': 0.1111111111111111, 'application': 0.1111111111111111, 'systems': 0.7777777777777778, 'extensive': 0.1111111111111111, 'helping': 0.1111111111111111, 'quick': 0.1111111111111111, 'understanding': 0.2222222222222222, 'article': 0.1111111111111111, 'saving': 0.1111111111111111, 'time': 0.1111111111111111, 'analysts': 0.1111111111111111, 'researchers': 0.1111111111111111, 'gathering': 0.1111111111111111, 'reducing': 0.2222222222222222, 'written': 0.1111111111111111, 'students': 0.1111111111111111, 'need': 0.2222222222222222, 'read': 0.2222222222222222, 'understand': 0.1111111111111111, 'educational': 0.1111111111111111, 'contexts': 0.1111111111111111, 'increasing': 0.1111111111111111, 'efficiency': 0.1111111111111111, 'productivity': 0.1111111111111111, 'business': 0.1111111111111111, 'settingsSome': 0.1111111111111111, 'automatic': 0.3333333333333333, 'use': 0.3333333333333333, 'order': 0.2222222222222222, 'identify': 0.2222222222222222, 'important': 0.1111111111111111, 'sentences': 0.6666666666666666, 'abstracts': 0.1111111111111111, 'key': 0.2222222222222222, 'like': 0.1111111111111111, 'structures': 0.1111111111111111, 'available': 0.1111111111111111, 'produce': 0.3333333333333333, 'summaries': 0.2222222222222222, 'grammatically': 0.1111111111111111, 'correct': 0.2222222222222222, 'tend': 0.1111111111111111, 'fragments': 0.1111111111111111, 'texts': 0.2222222222222222, 'inserted': 0.1111111111111111, 'help': 0.1111111111111111, 'convey': 0.1111111111111111, 'main': 0.2222222222222222, 'points': 0.2222222222222222, 'language': 0.3333333333333333, 'model': 0.2222222222222222, 'capture': 0.2222222222222222, 'meaning': 0.2222222222222222, 'grammatical': 0.1111111111111111, 'ensure': 0.1111111111111111, 'syntactically': 0.1111111111111111, 'hybrid': 0.1111111111111111, 'approaches': 0.1111111111111111, 'combine': 0.1111111111111111, 'models': 0.2222222222222222, 'grammar': 0.1111111111111111, 'trend': 0.1111111111111111, 'recent': 0.1111111111111111, 'research': 0.1111111111111111, 'natural': 0.1111111111111111, 'processing': 0.1111111111111111, 'NLP': 0.1111111111111111, 'techniques': 0.1111111111111111, 'automated': 0.1111111111111111, 'style': 0.1111111111111111, 'categorized': 0.1111111111111111, 'based': 0.3333333333333333, 'extracting': 0.1111111111111111, 'abstracting': 0.1111111111111111, 'Abstraction': 0.1111111111111111, 'summarizers': 0.2222222222222222, 'extract': 0.1111111111111111, 'representative': 0.1111111111111111, 'selected': 0.1111111111111111, 'portion': 0.1111111111111111, 'extraction': 0.1111111111111111, 'set': 0.1111111111111111, 'relevant': 0.1111111111111111, 'topic': 0.1111111111111111, 'effectiveness': 0.1111111111111111, 'depends': 0.1111111111111111, 'factors': 0.1111111111111111, 'type': 0.1111111111111111, 'algorithm': 0.1111111111111111, 'user': 0.1111111111111111, 'preferences': 0.1111111111111111, 'overall': 0.1111111111111111, 'found': 0.1111111111111111, 'effective': 0.1111111111111111, 'readers': 0.1111111111111111}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = [sent for sent in doc.sents]\n",
        "sentence_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym6WHnBqSx2s",
        "outputId": "e5526701-70d0-482b-c114-a6f3e0151b00"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Summarization is a process of automatically condensing and rewriting a large chunk of text to create a small, crisp summary.,\n",
              " A summarization system should give the reader most of the information present in the original document while also ensuring that no information has been lost during condensation.,\n",
              " The application of summarization systems is extensive, such as: helping the reader to get a quick understanding of an article, saving time for analysts and researchers in their information-gathering process, reducing the amount of written text that students need to read and understand (in educational contexts), and even increasing efficiency and productivity in business settingsSome systems for automatic summarization use full text in order to identify important sentences.,\n",
              " Other systems use abstracts, key sentences or other summary-like structures when the full text is not available.,\n",
              " Some automatic summarization systems produce summaries that are grammatically correct, while others tend to produce fragments of the original texts with some inserted sentences to help convey the main points.,\n",
              " Some automatic summarization systems use a language model to capture the meaning of sentences and a grammatical model to ensure that they are syntactically correct; there are also hybrid approaches that combine both language models and grammar models.,\n",
              " A trend in recent research has been towards using natural language processing (NLP) techniques for automated summarization of text in order to capture both the meaning and the style of the original document.,\n",
              " Summarization systems can be categorized based on whether they produce their summaries by extracting or abstracting information from the full texts.,\n",
              " Abstraction-based summarizers extract sentences that are representative of some selected portion of the full text, while extraction-based summarizers identify a set of key sentences that are most relevant to the topic of the document.,\n",
              " The effectiveness of a summarization system depends on several factors, such as the type of text, the summarization algorithm used, and the user preferences.,\n",
              " However, overall, summarization systems have been found to be effective in reducing the amount of text that readers need to read to get an understanding of the main points of a document.]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores = {}\n",
        "for sent in sentence_tokens:\n",
        "    for word in sent:\n",
        "        if word.text.lower() in word_frequencies.keys():\n",
        "           if sent not in sentence_scores.keys():\n",
        "               sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "           else:\n",
        "               sentence_scores[sent] += word_frequencies[word.text.lower()]"
      ],
      "metadata": {
        "id": "lGTpWHy_TFCl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z4tJaKqWQze",
        "outputId": "d30aeee2-bd6e-4893-9c7b-e726e5c24f82"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Summarization is a process of automatically condensing and rewriting a large chunk of text to create a small, crisp summary.: 3.2222222222222228,\n",
              " A summarization system should give the reader most of the information present in the original document while also ensuring that no information has been lost during condensation.: 3.5555555555555554,\n",
              " The application of summarization systems is extensive, such as: helping the reader to get a quick understanding of an article, saving time for analysts and researchers in their information-gathering process, reducing the amount of written text that students need to read and understand (in educational contexts), and even increasing efficiency and productivity in business settingsSome systems for automatic summarization use full text in order to identify important sentences.: 11.111111111111105,\n",
              " Other systems use abstracts, key sentences or other summary-like structures when the full text is not available.: 3.555555555555556,\n",
              " Some automatic summarization systems produce summaries that are grammatically correct, while others tend to produce fragments of the original texts with some inserted sentences to help convey the main points.: 5.555555555555555,\n",
              " Some automatic summarization systems use a language model to capture the meaning of sentences and a grammatical model to ensure that they are syntactically correct; there are also hybrid approaches that combine both language models and grammar models.: 6.111111111111109,\n",
              " A trend in recent research has been towards using natural language processing (NLP) techniques for automated summarization of text in order to capture both the meaning and the style of the original document.: 4.555555555555556,\n",
              " Summarization systems can be categorized based on whether they produce their summaries by extracting or abstracting information from the full texts.: 3.666666666666667,\n",
              " Abstraction-based summarizers extract sentences that are representative of some selected portion of the full text, while extraction-based summarizers identify a set of key sentences that are most relevant to the topic of the document.: 5.111111111111112,\n",
              " The effectiveness of a summarization system depends on several factors, such as the type of text, the summarization algorithm used, and the user preferences.: 3.8888888888888893,\n",
              " However, overall, summarization systems have been found to be effective in reducing the amount of text that readers need to read to get an understanding of the main points of a document.: 4.888888888888889}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30 perent of sentence with max score\n",
        "\n",
        "from heapq import nlargest"
      ],
      "metadata": {
        "id": "pA5XCdBEWXn_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "select_length = int(len(sentence_tokens)*0.3)\n",
        "select_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpFd6K0geYZu",
        "outputId": "fb30c8e8-725c-45f0-b8b4-63799b39cb5b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = nlargest(select_length,sentence_scores,key=sentence_scores.get)"
      ],
      "metadata": {
        "id": "4f4OvTFBekQQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_LKz1Sxe4Qb",
        "outputId": "9172152d-9de7-47fd-d082-f3600394e5a9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[The application of summarization systems is extensive, such as: helping the reader to get a quick understanding of an article, saving time for analysts and researchers in their information-gathering process, reducing the amount of written text that students need to read and understand (in educational contexts), and even increasing efficiency and productivity in business settingsSome systems for automatic summarization use full text in order to identify important sentences.,\n",
              " Some automatic summarization systems use a language model to capture the meaning of sentences and a grammatical model to ensure that they are syntactically correct; there are also hybrid approaches that combine both language models and grammar models.,\n",
              " Some automatic summarization systems produce summaries that are grammatically correct, while others tend to produce fragments of the original texts with some inserted sentences to help convey the main points.]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_summary = [word.text for word in summary]"
      ],
      "metadata": {
        "id": "lSNLvr6Ke5il"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = ' '.join(final_summary)"
      ],
      "metadata": {
        "id": "kxGbADtAfUj5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "7o2pN6Tkfe-X",
        "outputId": "55255174-a2bb-43dd-837d-970ff82cf3d6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The application of summarization systems is extensive, such as: helping the reader to get a quick understanding of an article, saving time for analysts and researchers in their information-gathering process, reducing the amount of written text that students need to read and understand (in educational contexts), and even increasing efficiency and productivity in business settingsSome systems for automatic summarization use full text in order to identify important sentences. Some automatic summarization systems use a language model to capture the meaning of sentences and a grammatical model to ensure that they are syntactically correct; there are also hybrid approaches that combine both language models and grammar models. Some automatic summarization systems produce summaries that are grammatically correct, while others tend to produce fragments of the original texts with some inserted sentences to help convey the main points.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55YCSUCOfgoO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}